{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-NuICG6r4Bi"
   },
   "source": [
    "Ćwiczenie wstępne z MPI. Na podstawie:\n",
    "* http://selkie.macalester.edu/DistributedPython/index.html\n",
    "\n",
    "* https://mpi4py.readthedocs.io/en/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oFDYsaxVf3h6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: pip: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!pip install mpi4py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvAAOle4ga5C",
    "outputId": "6b657d7d-9592-4c19-8187-828def4b8ee2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting example0.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile example0.py\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from mpi4py import MPI\n",
    "\n",
    "def main():\n",
    "  comm = MPI.COMM_WORLD # komunikator zawierający wszystkie procesy\n",
    "  id = comm.Get_rank() # id aktualnego procesu\n",
    "  numProc = comm.Get_size() # liczba procesów w komunikatorze\n",
    "  hostName = MPI.Get_processor_name() # nazwa maszyny na której uruchamiany jest program\n",
    "\n",
    "  print(f\"Jestem procesem nr {id} z {numProc} uruchamianym na maszynie {hostName}\")\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KytNw2hRijaN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jestem procesem nr 0 z 1 uruchamianym na maszynie DESKTOP-6S2SSNU\r\n",
      "Jestem procesem nr 0 z 1 uruchamianym na maszynie DESKTOP-6S2SSNU\r\n",
      "Jestem procesem nr 0 z 1 uruchamianym na maszynie DESKTOP-6S2SSNU\r\n",
      "Jestem procesem nr 0 z 1 uruchamianym na maszynie DESKTOP-6S2SSNU\r\n"
     ]
    }
   ],
   "source": [
    "#uruchomienie na komputrze lokalnym:\n",
    "# mpirun -np 4 python example0.py \n",
    "# ! oraz opcja --allow-run-as-root dodane na potrzeby notatnika\n",
    "!mpirun.mpich  -np 4 python3 example0.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SROxFakHjYvy",
    "outputId": "03dac79a-da46-4101-ea05-d836fd7bed20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing example1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile example1.py\n",
    "\n",
    "from mpi4py import MPI\n",
    "\n",
    "def main():\n",
    "  comm = MPI.COMM_WORLD # komunikator zawierający wszystkie procesy\n",
    "  id = comm.Get_rank() # id aktualnego procesu\n",
    "  numProc = comm.Get_size() # liczba procesów w komunikatorze\n",
    "  hostName = MPI.Get_processor_name() # nazwa maszyny na której uruchamiany jest program\n",
    "\n",
    "  if id == 0:\n",
    "    print(f\"Jestem procesem ** głównym ** o id {id} uruchamianym na maszynie {hostName}\")\n",
    "  else:\n",
    "    print(f\"Jestem procesem nr {id} z {numProc} uruchamianym na maszynie {hostName}\")\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "c1Veg0nnppef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jestem procesem ** głównym ** o id 0 uruchamianym na maszynie DESKTOP-6S2SSNU\n",
      "Jestem procesem ** głównym ** o id 0 uruchamianym na maszynie DESKTOP-6S2SSNU\n",
      "Jestem procesem ** głównym ** o id 0 uruchamianym na maszynie DESKTOP-6S2SSNU\n",
      "Jestem procesem ** głównym ** o id 0 uruchamianym na maszynie DESKTOP-6S2SSNU\n"
     ]
    }
   ],
   "source": [
    "!mpirun.mpich  -np 4 python3 example1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m9ZbA1HHbLnC",
    "outputId": "01766f53-959d-4574-e1e4-cf92493f9cb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting example2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile example2.py\n",
    "from mpi4py import MPI\n",
    "\n",
    "def main():\n",
    "    comm = MPI.COMM_WORLD\n",
    "    id = comm.Get_rank()            # numer procesu\n",
    "    numProcesses = comm.Get_size()  # łączna liczba procesów\n",
    "    myHostName = MPI.Get_processor_name()  # nazwa maszyny\n",
    "\n",
    "    REPS = 16\n",
    "\n",
    "    if ((REPS % numProcesses) == 0 and numProcesses <= REPS):\n",
    "        # określenie zakresu iteracji dla danego procesu\n",
    "        chunkSize = int(REPS / numProcesses)\n",
    "        start = id * chunkSize\n",
    "        stop = start + chunkSize\n",
    "\n",
    "        # wykonanie przypisanych iteracji\n",
    "        for i in range(start, stop):\n",
    "            print(\"On {}: Process {} is performing iteration {}\"\n",
    "                  .format(myHostName, id, i))\n",
    "    else:\n",
    "        # jeżeli nie da się podzielić iteracji równo\n",
    "        if id == 0:\n",
    "            print(\"Please run with number of processes divisible by \"\n",
    "                  \"and less than or equal to {}.\".format(REPS))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "YDsCPW6Kbho2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On DESKTOP-6S2SSNU: Process 0 is performing iteration 0\r\n",
      "On DESKTOP-6S2SSNU: Process 0 is performing iteration 1\r\n",
      "On DESKTOP-6S2SSNU: Process 0 is performing iteration 2\r\n",
      "On DESKTOP-6S2SSNU: Process 0 is performing iteration 3\r\n",
      "On DESKTOP-6S2SSNU: Process 0 is performing iteration 4\r\n",
      "On DESKTOP-6S2SSNU: Process 0 is performing iteration 5\r\n",
      "On DESKTOP-6S2SSNU: Process 0 is performing iteration 6\r\n",
      "On DESKTOP-6S2SSNU: Process 0 is performing iteration 7\r\n",
      "On DESKTOP-6S2SSNU: Process 0 is performing iteration 0\r\n",
      "On DESKTOP-6S2SSNU: Process 0 is performing iteration 1\r\n",
      "On DESKTOP-6S2SSNU: Process 0 is performing iteration 2\r\n",
      "On DESKTOP-6S2SSNU: Process 0 is performing iteration 3\r\n",
      "On DESKTOP-6S2SSNU: Process 0 is performing iteration 4\r\n",
      "On DESKTOP-6S2SSNU: Process 0 is performing iteration 5\r\n",
      "On DESKTOP-6S2SSNU: Process 0 is performing iteration 6\r\n",
      "On DESKTOP-6S2SSNU: Process 0 is performing iteration 7\r\n"
     ]
    }
   ],
   "source": [
    "!mpirun.mpich  -np 2 python3 example2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HuetR_Lmdqy9"
   },
   "source": [
    "\n",
    "*   Proszę uruchomić powyższy program użwając różnej liczby procesów (N = 1,2,4,8);  \n",
    "\n",
    "*   zmienić wartość REPS na 16\n",
    "* wyjaśnić jak schemat dzieli iteracje pętli między procesy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VoBgUYizeEk-",
    "outputId": "42481f23-f09d-4849-d0fb-13b14ba436e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting example3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile example3.py\n",
    "from mpi4py import MPI\n",
    "\n",
    "def main():\n",
    "    comm = MPI.COMM_WORLD\n",
    "    id = comm.Get_rank()            #number of the process running the code\n",
    "    numProcesses = comm.Get_size()  #total number of processes running\n",
    "    myHostName = MPI.Get_processor_name()  #machine name running the code\n",
    "\n",
    "    REPS = 16\n",
    "\n",
    "    if (numProcesses <= REPS):\n",
    "\n",
    "        for i in range(id, REPS, numProcesses):\n",
    "            print(\"On {}: Process {} is performing iteration {}\"\\\n",
    "            .format(myHostName, id, i))\n",
    "\n",
    "    else:\n",
    "        # can't have more processes than work; one process reports the error\n",
    "        if id == 0 :\n",
    "            print(\"Please run with number of processes less than \\\n",
    "or equal to {}.\".format(REPS))\n",
    "\n",
    "########## Run the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ERboKygpkmR_"
   },
   "outputs": [],
   "source": [
    "!mpirun.mpich  -np 4 python3 example3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMzhBSzwkziL"
   },
   "source": [
    "* Proszę uruchomić powyższy program użwając różnej liczby procesów (N = 1,2,4,8);\n",
    "\n",
    "* zmienić wartość REPS na 16\n",
    "\n",
    "* wyjaśnić jak schemat dzieli iteracje pętli między procesy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFTzISLrk7fW"
   },
   "source": [
    "Komunikacja punkt-punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qcQEJTCPk7J2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing example4.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile example4.py\n",
    "from mpi4py import MPI\n",
    "\n",
    "# function to return whether a number of a process is odd or even\n",
    "def odd(number):\n",
    "    if (number % 2) == 0:\n",
    "        return False\n",
    "    else :\n",
    "        return True\n",
    "\n",
    "def main():\n",
    "    comm = MPI.COMM_WORLD\n",
    "    id = comm.Get_rank()            #number of the process running the code\n",
    "    numProcesses = comm.Get_size()  #total number of processes running\n",
    "    myHostName = MPI.Get_processor_name()  #machine name running the code\n",
    "\n",
    "    if numProcesses > 1 and not odd(numProcesses):\n",
    "        #generate a list of 8 numbers, beginning with my id\n",
    "        sendList = list(range(id, id+8))\n",
    "        if odd(id):\n",
    "            #odd processes send to their 'left neighbor', then receive from\n",
    "            comm.send(sendList, dest=id-1)\n",
    "            receivedList = comm.recv(source=id-1)\n",
    "        else :\n",
    "            #even processes receive from their 'right neighbor', then send\n",
    "            receivedList = comm.recv(source=id+1)\n",
    "            comm.send(sendList, dest=id+1)\n",
    "\n",
    "        print(\"Process {} of {} on {} computed {} and received {}\"\\\n",
    "        .format(id, numProcesses, myHostName, sendList, receivedList))\n",
    "\n",
    "    else :\n",
    "        if id == 0:\n",
    "            print(\"Please run this program with the number of processes \\\n",
    "positive and even\")\n",
    "\n",
    "########## Run the main function\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PXQjxcgJoLVh"
   },
   "outputs": [],
   "source": [
    "!mpirun.mpich  -np 4 python3 example4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-YCBUkionZe"
   },
   "source": [
    "Proszę narysować schemat komunikacji pomiędzy poszczególnymi procesami w zadaniu numer 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kL8QLk7WpLIT"
   },
   "source": [
    "##Zadanie\n",
    "**Zadanie.** Proszę napisać program który generuje tablicę tablic liczb w procesie głównym i rozsyłą je do pozostałych procesów. Procesy odbierają swoją część tablicy i wyliczają oraz wypisują jej sumę;   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting zad.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile zad.py\n",
    "from mpi4py import MPI\n",
    "from random import randint\n",
    "\n",
    "def main():\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()   # numer procesu\n",
    "    size = comm.Get_size()   # łączna liczba procesów\n",
    "\n",
    "    if rank == 0:\n",
    "        data = []\n",
    "        # Tworzymy tablice tylko dla procesów od 1 do size-1\n",
    "        for x in range(1, size):\n",
    "            subList = []\n",
    "            for y in range(size):\n",
    "                subList.append(randint(0, y + x))\n",
    "            data.append(subList)\n",
    "        \n",
    "        # Wysyłamy odpowiednią tablicę do każdego procesu od 1 do size-1\n",
    "        for x in range(1, size):\n",
    "            # Dla procesu x dane przechowujemy w data[x-1]\n",
    "            comm.send(data[x-1], dest=x)\n",
    "    else:\n",
    "        recvList = comm.recv(source=0)\n",
    "        print(f\"For process {rank}, sum is {sum(recvList)}, list rec: {recvList}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "!mpirun.mpich  -np 4 python3 zad.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2Z18A5Kqz1P"
   },
   "source": [
    "Komunikacja kolektywna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BxmmtViDqzgR",
    "outputId": "33aa332b-3de4-42ba-8ac4-9f633217962b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing broadcast_example.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile broadcast_example.py\n",
    "from mpi4py import MPI\n",
    "\n",
    "def main():\n",
    "    comm = MPI.COMM_WORLD\n",
    "    id = comm.Get_rank()            #number of the process running the code\n",
    "    numProcesses = comm.Get_size()  #total number of processes running\n",
    "    myHostName = MPI.Get_processor_name()  #machine name running the code\n",
    "\n",
    "    if numProcesses > 1 :\n",
    "\n",
    "        if id == 0:        # master\n",
    "            #master: generate a dictionary with arbitrary data in it\n",
    "            data = list(range(numProcesses))\n",
    "            print(\"Master Process {} of {} on {} broadcasts {}\"\\\n",
    "            .format(id, numProcesses, myHostName, data))\n",
    "\n",
    "        else :\n",
    "            # worker: start with empty data\n",
    "            data = []\n",
    "            print(\"Worker Process {} of {} on {} starts with {}\"\\\n",
    "            .format(id, numProcesses, myHostName, data))\n",
    "\n",
    "        #initiate and complete the broadcast\n",
    "        data = comm.bcast(data, root=0)\n",
    "\n",
    "        #check the result\n",
    "        print(\"Process {} of {} on {} has {} after the broadcast\"\\\n",
    "        .format(id, numProcesses, myHostName, data))\n",
    "\n",
    "    else :\n",
    "        print(\"Please run this program with the number of processes greater than 1\")\n",
    "\n",
    "########## Run the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rRSNY-R7rZUj"
   },
   "outputs": [],
   "source": [
    "!mpirun.mpich  -np 4 python3 broadcast_example.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4iARvNErWQy"
   },
   "source": [
    "Scatter, Gather "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3RTlc4w1ruZx",
    "outputId": "9f53325c-4444-465a-d5bc-fe5e461050ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 14scatter.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 14scatter.py\n",
    "from mpi4py import MPI\n",
    "\n",
    "# Create a list of lists to be scattered.\n",
    "def genListOfLists(numElements):\n",
    "    data = [[0]*3 for i in range(numElements)]\n",
    "    for i in range(numElements):\n",
    "        #make small lists of 3 distinct elements\n",
    "        smallerList = []\n",
    "        for j in range(1,4):\n",
    "            smallerList = smallerList + [(i+1)*j]\n",
    "        # place the small list in the larger list\n",
    "        data[i] = smallerList\n",
    "    return data\n",
    "\n",
    "def main():\n",
    "    comm = MPI.COMM_WORLD\n",
    "    id = comm.Get_rank()            #number of the process running the code\n",
    "    numProcesses = comm.Get_size()  #total number of processes running\n",
    "    myHostName = MPI.Get_processor_name()  #machine name running the code\n",
    "\n",
    "    # in mpi4py, the lowercase scatter method only works on lists whose size\n",
    "    # is the total number of processes.\n",
    "    numElements = numProcesses      #total elements in list created by master process\n",
    "\n",
    "    # however, the list can contain lists, like this list of 3-element lists,\n",
    "    # for example this list of four 3-element lists:\n",
    "    #     [[1, 2, 3], [2, 4, 6], [3, 6, 9], [4, 8, 12]]\n",
    "\n",
    "    if id == 0:\n",
    "        data = genListOfLists(numElements)\n",
    "        print(\"Master {} of {} on {} has created list: {}\"\\\n",
    "        .format(id, numProcesses, myHostName, data))\n",
    "    else:\n",
    "        data = None\n",
    "        print(\"Worker Process {} of {} on {} starts with {}\"\\\n",
    "        .format(id, numProcesses, myHostName, data))\n",
    "\n",
    "    #scatter one small list in the large list on node 0 to each of the processes\n",
    "    result = comm.scatter(data, root=0)\n",
    "\n",
    "    print(\"Process {} of {} on {} has result after scatter {}\"\\\n",
    "    .format(id, numProcesses, myHostName, result))\n",
    "\n",
    "    if id == 0:\n",
    "        print(\"Master {} of {} on {} has original list after scatter: {}\"\\\n",
    "        .format(id, numProcesses, myHostName, data))\n",
    "\n",
    "########## Run the main function\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ItDGyYrqrxBA"
   },
   "outputs": [],
   "source": [
    "!mpirun.mpich  -np 4 python3 14scatter.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvCNDN56s71A"
   },
   "source": [
    "Zadanie. Proszę napisać program który generuje tablicę tablic liczb w procesie głównym i rozsyłą je do pozostałych procesów. Procesy odbierają swoją część tablicy i wyliczają oraz wypisują jej sumę. Proszę napisac program z wykorzystaniem komunikacji kolektywnej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting zad2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile zad2.py\n",
    "from mpi4py import MPI\n",
    "from random import randint\n",
    "\n",
    "def main():\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()   # numer procesu\n",
    "    size = comm.Get_size()   # łączna liczba procesów\n",
    "    data = []\n",
    "    if rank == 0:\n",
    "        for x in range(size):\n",
    "            subList = []\n",
    "            for y in range(size):\n",
    "                subList.append(randint(0, y + x))\n",
    "            data.append(subList)\n",
    "    else:\n",
    "        list = None\n",
    "        print(f\"Befor for procces {rank}, list is: {list}\")    \n",
    "    # Brodkast tablicy\n",
    "    list = comm.scatter(data, root=0)\n",
    "\n",
    "    \n",
    "    print(f\"For process {rank}, sum is {sum(list)}, list rec: {list}\")    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "PRIR_mpi4py.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
